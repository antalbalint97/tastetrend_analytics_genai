{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71956f11",
   "metadata": {},
   "source": [
    "# TasteTrend - AWS GenAI PoC Demo (End-to-End on AWS)\n",
    "\n",
    "This notebook demonstrates the deployed AWS architecture end-to-end:\n",
    "- ETL Lambda reads raw files from S3, standardizes them, and writes a processed dataset to S3.\n",
    "- Embedding Lambda generates Titan embeddings and upserts vectors into Amazon OpenSearch.\n",
    "- Retrieval lambda is available for Bedrock Agent action group calls.\n",
    "- The public Query API (API Gateway + Proxy Lambda + Bedrock Agent) answers business questions over the indexed data.\n",
    "- Automated evaluation runs accuracy and latency checks against a small gold set.\n",
    "\n",
    "Prerequisites:\n",
    "- AWS credentials configured for the target account and region with permissions to invoke the Lambdas and read S3.\n",
    "- The infrastructure has been deployed via Terraform (S3 buckets, Lambdas, OpenSearch, API Gateway, Bedrock Agent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de880745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup environment\n",
    "import os, sys, json, time\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load local .env if present\n",
    "load_dotenv()\n",
    "\n",
    "# Make src importable\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# --- User-editable configuration (use values from your Terraform outputs) ---\n",
    "AWS_REGION = os.environ.get(\"AWS_REGION\", \"eu-central-1\")\n",
    "RAW_BUCKET = os.environ.get(\"TT_RAW_BUCKET\", \"<your-raw-bucket-name>\")\n",
    "PROCESSED_BUCKET = os.environ.get(\"TT_PROCESSED_BUCKET\", \"<your-processed-bucket-name>\")\n",
    "\n",
    "ETL_LAMBDA_NAME     = os.environ.get(\"TT_ETL_LAMBDA\", \"tt-etl-handler\")\n",
    "EMBED_LAMBDA_NAME   = os.environ.get(\"TT_EMBED_LAMBDA\", \"tt-embed-handler\")\n",
    "SEARCH_LAMBDA_NAME  = os.environ.get(\"TT_SEARCH_LAMBDA\", \"tt-search-reviews-handler\")\n",
    "\n",
    "# Public API Gateway base URL for Bedrock Agent proxy (no trailing slash)\n",
    "os.environ.setdefault(\"TT_API_URL\", os.environ.get(\"TT_API_URL\", \"https://your-api-id.execute-api.eu-central-1.amazonaws.com/prod\"))\n",
    "if not os.getenv(\"TT_API_KEY\"):\n",
    "    os.environ[\"TT_API_KEY\"] = getpass(\"Please enter your TasteTrend API key: \")\n",
    "\n",
    "print(\"Environment ready.\")\n",
    "print(\"AWS_REGION:\", AWS_REGION)\n",
    "print(\"RAW_BUCKET:\", RAW_BUCKET)\n",
    "print(\"PROCESSED_BUCKET:\", PROCESSED_BUCKET)\n",
    "print(\"ETL_LAMBDA_NAME:\", ETL_LAMBDA_NAME)\n",
    "print(\"EMBED_LAMBDA_NAME:\", EMBED_LAMBDA_NAME)\n",
    "print(\"SEARCH_LAMBDA_NAME:\", SEARCH_LAMBDA_NAME)\n",
    "print(\"TT_API_URL:\", os.getenv(\"TT_API_URL\"))\n",
    "print(\"TT_API_KEY loaded:\", bool(os.getenv(\"TT_API_KEY\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18519b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Optional: list raw S3 files to confirm inputs\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "resp = s3.list_objects_v2(Bucket=RAW_BUCKET)\n",
    "print(\"Objects in raw bucket:\")\n",
    "for obj in resp.get(\"Contents\", []):\n",
    "    print(\" -\", obj[\"Key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run ETL on AWS Lambda (reads from RAW_BUCKET, writes to PROCESSED_BUCKET)\n",
    "import boto3, json\n",
    "\n",
    "lambda_client = boto3.client(\"lambda\", region_name=AWS_REGION)\n",
    "\n",
    "etl_event = {\n",
    "    # Your ETL lambda reads RAW_BUCKET and writes processed file(s) to PROCESSED_BUCKET.\n",
    "    # No extra payload is strictly required if the lambda uses env vars. This is here for traceability.\n",
    "    \"raw_bucket\": RAW_BUCKET,\n",
    "    \"processed_bucket\": PROCESSED_BUCKET\n",
    "}\n",
    "\n",
    "print(\"Invoking ETL lambda:\", ETL_LAMBDA_NAME)\n",
    "etl_resp = lambda_client.invoke(\n",
    "    FunctionName=ETL_LAMBDA_NAME,\n",
    "    InvocationType=\"RequestResponse\",\n",
    "    Payload=json.dumps(etl_event).encode(\"utf-8\"),\n",
    ")\n",
    "etl_payload = etl_resp[\"Payload\"].read().decode(\"utf-8\")\n",
    "print(\"ETL response:\", etl_payload)\n",
    "\n",
    "# The ETL lambda writes a processed dataset. We expect a file like 'processed_final.csv' in the processed bucket.\n",
    "processed_key = \"processed_final.csv\"  # keep in sync with your lambda\n",
    "print(\"Expected processed key:\", processed_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9508942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preview first few lines of the processed dataset in S3\n",
    "import io, csv\n",
    "\n",
    "obj = s3.get_object(Bucket=PROCESSED_BUCKET, Key=processed_key)\n",
    "body = obj[\"Body\"].read().decode(\"utf-8\", errors=\"replace\")\n",
    "\n",
    "reader = csv.reader(io.StringIO(body))\n",
    "rows = []\n",
    "for i, row in enumerate(reader):\n",
    "    rows.append(row)\n",
    "    if i >= 5:\n",
    "        break\n",
    "\n",
    "print(\"Processed file preview (first 6 rows):\")\n",
    "for r in rows:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483092af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Embedding and indexing step on AWS Lambda (Bedrock -> OpenSearch upsert)\n",
    "# This calls your embedding lambda with the S3 CSV the ETL produced.\n",
    "import json\n",
    "\n",
    "embed_event = {\n",
    "    \"s3_csv_uri\": f\"s3://{PROCESSED_BUCKET}/{processed_key}\",\n",
    "    # Optionally override index name if your lambda supports it\n",
    "    # \"os_index\": \"reviews_v2\"\n",
    "}\n",
    "\n",
    "print(\"Invoking Embedding lambda:\", EMBED_LAMBDA_NAME)\n",
    "embed_resp = lambda_client.invoke(\n",
    "    FunctionName=EMBED_LAMBDA_NAME,\n",
    "    InvocationType=\"RequestResponse\",\n",
    "    Payload=json.dumps(embed_event).encode(\"utf-8\"),\n",
    ")\n",
    "embed_payload = embed_resp[\"Payload\"].read().decode(\"utf-8\")\n",
    "print(\"Embedding response:\", embed_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff27ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Optional: directly invoke vector search lambda (as used by the Bedrock Agent action group)\n",
    "search_query = \"Great food but slow service. What location is that likely about?\"\n",
    "\n",
    "search_event = {\n",
    "    \"body\": json.dumps({\"query\": search_query})\n",
    "}\n",
    "\n",
    "print(\"Invoking Search lambda:\", SEARCH_LAMBDA_NAME)\n",
    "search_resp = lambda_client.invoke(\n",
    "    FunctionName=SEARCH_LAMBDA_NAME,\n",
    "    InvocationType=\"RequestResponse\",\n",
    "    Payload=json.dumps(search_event).encode(\"utf-8\"),\n",
    ")\n",
    "search_payload = search_resp[\"Payload\"].read().decode(\"utf-8\")\n",
    "print(\"Search response:\", search_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d178e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Public Query API (API Gateway + Proxy Lambda + Bedrock Agent)\n",
    "# Uses src/api/query_client.py\n",
    "from api.query_client import ask\n",
    "\n",
    "query = \"What do customers like most about the Uptown location?\"\n",
    "answer, refs, ms = ask(query)\n",
    "print(f\"{ms:.0f} ms | {answer}\\nReferences: {refs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b1b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Automated evaluation (Bedrock embeddings for semantic metric)\n",
    "from api.eval import run_eval\n",
    "import json\n",
    "\n",
    "questions = [\n",
    "    \"What is the best restaurant overall?\",\n",
    "    \"What is the general consensus of the downtown restaurant?\",\n",
    "    \"What do customers like most about the Uptown location?\",\n",
    "    \"What do people complain about in the Riverside restaurant?\",\n",
    "    \"How does service quality compare between Uptown and Riverside?\",\n",
    "]\n",
    "\n",
    "results = run_eval(questions)\n",
    "print(json.dumps(results, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad35e5",
   "metadata": {},
   "source": [
    "# 9. MVP Plan and Cost\n",
    "\n",
    "| Component | AWS Service | Est. Monthly Cost | Notes |\n",
    "|------------|--------------|------------------|--------|\n",
    "| Storage | Amazon S3 | ~$1 | Raw and processed data. Free Tier covers small PoC. |\n",
    "| Compute | AWS Lambda | <$5 | ETL, Embedding, Search, Proxy. |\n",
    "| Vector DB | Amazon OpenSearch Service | ~$15 | Small single-node for vectors. |\n",
    "| GenAI | Amazon Bedrock (Titan Embeddings) | ~$10–20 | Depends on volume of embeddings and queries. |\n",
    "| API Layer | Amazon API Gateway | <$5 | Public query endpoint. |\n",
    "| Monitoring & Security | CloudWatch, IAM, KMS | ~$2 | Basic logs and encryption. |\n",
    "| Total (MVP estimate) |  | **~$30–45** | Low-cost PoC; scales with data and traffic. |\n",
    "\n",
    "Next steps:\n",
    "- Add real-time ingestion from review platforms.\n",
    "- Build a dashboard for business users.\n",
    "- Implement multi-tenant access and authentication.\n",
    "- Automate daily refresh and extend analytics.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
